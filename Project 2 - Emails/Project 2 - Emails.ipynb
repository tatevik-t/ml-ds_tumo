{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Spam/Ham Prediction\n",
    "\n",
    "In this project, we will create a classifier that can distinguish spam emails from ham (non-spam) emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Data\n",
    "\n",
    "The dataset consists of email messages and their labels (0 for ham, 1 for spam)\n",
    "\n",
    "The `emails` DataFrame contains labeled data that we will use to train your model. It contains three columns:\n",
    "\n",
    "1. `id`: An identifier for the training example.\n",
    "1. `subject`: The subject of the email\n",
    "1. `email`: The text of the email.\n",
    "1. `spam`: 1 if the email was spam, 0 if the email was ham (not spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>subject: a&amp;l daily to be auctioned in bankrupt...</td>\n",
       "      <td>url: http://boingboing.net/#85534171\\n date: n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>subject: wired: \"stronger ties between isps an...</td>\n",
       "      <td>url: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>subject: it's just too small                  ...</td>\n",
       "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;font siz...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>subject: liberal defnitions\\n</td>\n",
       "      <td>depends on how much over spending vs. how much...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>subject: re: [ilug] newbie seeks advice - suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  subject: a&l daily to be auctioned in bankrupt...   \n",
       "1   1  subject: wired: \"stronger ties between isps an...   \n",
       "2   2  subject: it's just too small                  ...   \n",
       "3   3                      subject: liberal defnitions\\n   \n",
       "4   4  subject: re: [ilug] newbie seeks advice - suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  url: http://boingboing.net/#85534171\\n date: n...   0.0  \n",
       "1  url: http://scriptingnews.userland.com/backiss...   0.0  \n",
       "2  <html>\\n <head>\\n </head>\\n <body>\\n <font siz...   1.0  \n",
       "3  depends on how much over spending vs. how much...   0.0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...   0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "# We lower case the emails to make them easier to work with\n",
    "train['email'] = train['email'].str.lower()\n",
    "train['subject'] = train['subject'].str.lower()\n",
    "train=train[0:8013]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Features\n",
    "\n",
    "We would like to take the text of an email and predict whether the text is ham or spam. This is a *classification* problem, so we will use logistic regression to make a classifier.\n",
    "\n",
    "data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression.\n",
    "\n",
    "We create a function called `words_in_text` that takes in a list of words and the text of an email. It outputs a pandas Series containing either a 0 or a 1 for each word in the list. The value of the Series should be 0 if the word doesn't appear in the text and 1 if the word does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def words_in_text(words, text):\n",
    "    '''\n",
    "    Args:\n",
    "        `words` (list of str): words to find\n",
    "        `text` (str): string to search in\n",
    "    \n",
    "    Returns:\n",
    "        Series containing either 0 or 1 for each word in words\n",
    "        (0 if the word is not in text, 1 if the word is).\n",
    "    '''\n",
    "    return pd.Series([1 if str(word) in str(text) else 0 for word in words])\n",
    "\n",
    "\n",
    "assert np.allclose(words_in_text(['hello'], 'hello world'),\n",
    "                   [1])\n",
    "assert np.allclose(words_in_text(['hello', 'bye', 'world'], 'hello world hello'),\n",
    "                   [1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a function called `words_in_texts` that takes in a list of words and a pandas Series of email texts. It should output a 2-dimensional NumPy matrix containing one row for each email text. The row should contain the output of `words_in_text` for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        `words` (list of str): words to find\n",
    "        `texts` (Series of str): strings to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "    '''\n",
    "    return np.matrix([words_in_text(words, text) for text in texts])\n",
    "\n",
    "assert np.allclose(words_in_texts(['hello', 'bye', 'world'], pd.Series(['hello', 'hello world hello'])),\n",
    "                   np.array([[1, 0, 0], [1, 0, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "The output of `words_in_texts` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier.\n",
    "\n",
    "The following 5 words might be useful as features to distinguish spam/ham emails. We use these words as well as the `train` DataFrame to create two NumPy arrays: `X_train` and `y_train`.\n",
    "\n",
    "`X_train` should be a matrix of 0s and 1s created by using our `words_in_texts` function on all the emails in the training set.\n",
    "\n",
    "`y_train` should be vector of the correct labels for each email in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "some_words = ['drug','bank','prescription','memo','private']\n",
    "X_train = words_in_texts(some_words, train[\"email\"])\n",
    "y_train = train[\"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have matrices we can give to scikit-learn! Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, we train a logistic regression model using `X_train` and `y_train`. Then, we output the accuracy of the model in the cell below. We get the accuracy around 75.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.63958567328092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "clf = lr.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "acc = np.count_nonzero(y_pred==train[\"spam\"])/train.shape[0]*100\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't seem too shabby! But the classifier we made above isn't as great as we might think. \n",
    "We calculate the proportion of ham emails and compare it to the accuracy you got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450393111194309"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_emails = np.count_nonzero(1-train['spam'])/train.shape[0]\n",
    "ham_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward\n",
    "\n",
    "With this in mind, it was our assignment to make our classifier more accurate. In particular, everybody in the class should get at least **88%** accuracy on the test set.\n",
    "\n",
    "Here are some ideas for improving our model:\n",
    "\n",
    "1. Finding better features based on the email text. For example, simple features that typically work for emails are:\n",
    "    1. Number of characters in the subject / body\n",
    "    1. Number of words in the subject / body\n",
    "    1. Use of punctuation (e.g., how many '!' were there?)\n",
    "    1. Whether or not the email is a reply to an earlier email or a forwarded email. \n",
    "    1. Using bag-of-words or [td-idf](http://www.tfidf.com/).\n",
    "    \n",
    "1. Finding better words to use as features. Which words are the best at distinguishing emails? This requires digging into the email text itself. (To help you out, we've given you a set of [English stopwords](https://www.wikiwand.com/en/Stop_words) in `stopwords.csv`)\n",
    "1. Better data processing. For example, many emails contain HTML as well as text. You can consider extracting out the text from the HTML to help you find better words. Or, you can match HTML tags themselves, or even some combination of the two.\n",
    "\n",
    "Recall that we should use cross-validation to do feature and model selection properly! Otherwise, we will likely overfit to our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we tried to use various research publications found on the internet that contained recommendations for word feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Work Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def count(string, text):\n",
    "    return text.count(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('stopwords.csv')\n",
    "some_words = ['bank','prescription','private',\"free\",\"dear\",\"yours\",\n",
    "              \"img=\",\"html\",\"</\",\" </div>\",\"</table>\",\"url=\",\"http://www.\",\"value=\",\"<!--\",r'\\<.*\\>',r\"#[a-f0-9]{6}\",\n",
    "              \"$\",\"+\",\"-\",\"  \",\"\\\\\",\"@\",\"|\",'\"\"',\"'\",\"$$\"]\n",
    "#some_words += list(stopwords)\n",
    "\n",
    "x_train = words_in_texts(some_words, train[\"email\"])\n",
    "#x_train = np.append(x_train1,np.array([]).T, 1)\n",
    "\n",
    "#print(x_train.shape[1])\n",
    "\n",
    "y_train = train[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8013, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_find = words_in_texts([\"re: \"], pd.Series(train[\"subject\"]))\n",
    "virus_find = words_in_texts([\"virus\"], pd.Series(train[\"subject\"]))\n",
    "\n",
    "x_train = np.concatenate((x_train, np.array(re_find)), axis=1)\n",
    "x_train = np.concatenate((x_train, np.array(virus_find)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_html=r'\\<.*\\>'\n",
    "arr=train[\"email\"].str.count(re_html)\n",
    "x_train=np.append(x_train,np.array([arr]).T,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_c = r'\\b([a-zA-Z]+[0-9]+[a-zA-Z0-9]*|[0-9]+[a-zA-Z]+[a-zA-Z0-9]*)\\b'\n",
    "arr=train[\"email\"].str.count(re_html)\n",
    "x_train=np.append(x_train,np.array([arr]).T, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.50444041018596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#Your code here\n",
    "lr = LogisticRegression()\n",
    "clf = lr.fit(x_train, y_train)\n",
    "y_pred=clf.predict(x_train)\n",
    "hamemat = np.count_nonzero(y_pred==y_train)\n",
    "hamemat / train.shape[0] * 100\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "accuracy=0\n",
    "for train1, test in kf.split(x_train):\n",
    "    cv_x_train=x_train[train1]\n",
    "    cv_y_train=y_train[train1]\n",
    "    cv_x_test=x_train[test]\n",
    "    cv_y_test=y_train[test]\n",
    "    lr=  LogisticRegression()\n",
    "    lr.fit(cv_x_train, cv_y_train)\n",
    "    cv_y_pred=lr.predict(cv_x_test)\n",
    "    cv_test_error = np.count_nonzero(cv_y_pred==cv_y_test)/len(cv_y_test)\n",
    "    accuracy=cv_test_error+accuracy\n",
    "accuracy/5 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! We got 89% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "In the four light blue cells below, show four different visualizations that you used to select features for your model. Each cell should output:\n",
    "\n",
    "1. A plot showing something meaningful about the data that helped you during feature / model selection.\n",
    "2. 2-3 sentences describing what you plotted and what its implications are for your features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluating your work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everybody is finished, I will give you intructions for evaluating your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: Industry Forum #136</td>\n",
       "      <td>This is an HTML email message.  If you see thi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: please help, new webcam/ modeling page\\n</td>\n",
       "      <td>I just got a webcam and computer for my birthd...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: [ILUG] HELLO\\n</td>\n",
       "      <td>OFFICE OF:EGNR. FEMI DANIEL\\n FEDERAL MINISTRY...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: Re: [ILUG] Alan Cox doesn't like 2.5 ...</td>\n",
       "      <td>&gt; The impression I get from reading lkml the o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: Re: Holidays for freshrpms.net :-)\\n</td>\n",
       "      <td>On Tue, 10 Sep 2002 18:39:07 +0200\\n Matthias ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "1                       Subject: Industry Forum #136   \n",
       "2  Subject: please help, new webcam/ modeling page\\n   \n",
       "3                            Subject: [ILUG] HELLO\\n   \n",
       "4  Subject: Re: [ILUG] Alan Cox doesn't like 2.5 ...   \n",
       "5      Subject: Re: Holidays for freshrpms.net :-)\\n   \n",
       "\n",
       "                                               email  spam  \n",
       "1  This is an HTML email message.  If you see thi...   1.0  \n",
       "2  I just got a webcam and computer for my birthd...   1.0  \n",
       "3  OFFICE OF:EGNR. FEMI DANIEL\\n FEDERAL MINISTRY...   1.0  \n",
       "4  > The impression I get from reading lkml the o...   0.0  \n",
       "5  On Tue, 10 Sep 2002 18:39:07 +0200\\n Matthias ...   0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\", names=[\"subject\", \"email\", \"spam\", \"0\", \"1\", \"2\", \"3\"], header=None).iloc[1:,0:3]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('stopwords.csv')\n",
    "some_words = ['bank','prescription','private',\"free\",\"dear\",\"yours\",\n",
    "              \"img=\",\"html\",\"</\",\" </div>\",\"</table>\",\"url=\",\"http://www.\",\"value=\",\"<!--\",r'\\<.*\\>',r\"#[a-f0-9]{6}\",\n",
    "              \"$\",\"+\",\"-\",\"  \",\"\\\\\",\"@\",\"|\",'\"\"',\"'\",\"$$\"]\n",
    "#some_words += list(stopwords)\n",
    "\n",
    "x_test = words_in_texts(some_words, test[\"email\"])\n",
    "\n",
    "#print(x_test.shape[1])\n",
    "\n",
    "y_test = test[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_find = words_in_texts([\"re: \"], pd.Series(test[\"subject\"]))\n",
    "virus_find = words_in_texts([\"virus\"], pd.Series(test[\"subject\"]))\n",
    "\n",
    "x_test = np.concatenate((x_test, np.array(re_find)), axis=1)\n",
    "x_test = np.concatenate((x_test, np.array(virus_find)), axis=1)\n",
    "\n",
    "#print(x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_html=r'\\<.*\\>'\n",
    "arr = test[\"email\"].str.count(re_html)\n",
    "x_test = np.append(x_test,np.array([arr]).T,1)\n",
    "\n",
    "#print(x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "re_c = r'\\b([a-zA-Z]+[0-9]+[a-zA-Z0-9]*|[0-9]+[a-zA-Z]+[a-zA-Z0-9]*)\\b'\n",
    "arr = test[\"email\"].str.count(re_html)\n",
    "x_test = np.append(x_test,np.array([arr]).T, 1)\n",
    "\n",
    "print(x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 31) (8013, 31)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.97014925373134"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "clf = lr.fit(x_train, y_train)\n",
    "y_pred_test = clf.predict(x_test)\n",
    "\n",
    "acc = np.count_nonzero(y_test==y_pred_test)/test.shape[0]*100\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 85.9% accuracy on test data. Good job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
